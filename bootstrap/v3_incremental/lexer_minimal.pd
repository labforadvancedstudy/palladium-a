// Minimal lexer for bootstrap - no references, no Vec, no match
// Global state approach for simplicity

// Constants
const MAX_TOKENS: i64 = 10000;
const MAX_INPUT: i64 = 100000;
const MAX_STRING_TABLE: i64 = 100000;

// Token types
const TOK_EOF: i64 = 0;
const TOK_IDENT: i64 = 1;
const TOK_NUMBER: i64 = 2;
const TOK_STRING: i64 = 3;
const TOK_FN: i64 = 4;
const TOK_LET: i64 = 5;
const TOK_MUT: i64 = 6;
const TOK_IF: i64 = 7;
const TOK_ELSE: i64 = 8;
const TOK_WHILE: i64 = 9;
const TOK_RETURN: i64 = 10;
const TOK_TRUE: i64 = 11;
const TOK_FALSE: i64 = 12;
const TOK_STRUCT: i64 = 13;
const TOK_ENUM: i64 = 14;
const TOK_PUB: i64 = 15;
const TOK_IMPORT: i64 = 16;
const TOK_I64: i64 = 17;
const TOK_I32: i64 = 18;
const TOK_BOOL: i64 = 19;
const TOK_STRING_TYPE: i64 = 20;
const TOK_LPAREN: i64 = 21;
const TOK_RPAREN: i64 = 22;
const TOK_LBRACE: i64 = 23;
const TOK_RBRACE: i64 = 24;
const TOK_LBRACKET: i64 = 25;
const TOK_RBRACKET: i64 = 26;
const TOK_SEMICOLON: i64 = 27;
const TOK_COMMA: i64 = 28;
const TOK_DOT: i64 = 29;
const TOK_COLON: i64 = 30;
const TOK_ARROW: i64 = 31;
const TOK_EQ: i64 = 32;
const TOK_PLUS: i64 = 33;
const TOK_MINUS: i64 = 34;
const TOK_STAR: i64 = 35;
const TOK_SLASH: i64 = 36;
const TOK_PERCENT: i64 = 37;
const TOK_LT: i64 = 38;
const TOK_GT: i64 = 39;
const TOK_LE: i64 = 40;
const TOK_GE: i64 = 41;
const TOK_EQEQ: i64 = 42;
const TOK_NE: i64 = 43;
const TOK_AMPAMP: i64 = 44;
const TOK_PIPEPIPE: i64 = 45;
const TOK_BANG: i64 = 46;
const TOK_DOTDOT: i64 = 47;
const TOK_COLONCOLON: i64 = 48;
const TOK_FOR: i64 = 49;
const TOK_IN: i64 = 50;

// Token structure
struct Token {
    type: i64,
    value: i64,  // For numbers or string table offset
    line: i64,
    column: i64,
}

// Global lexer state
let mut INPUT: [i64; MAX_INPUT] = [0; MAX_INPUT];
let mut INPUT_LEN: i64 = 0;
let mut INPUT_POS: i64 = 0;
let mut CURRENT_LINE: i64 = 1;
let mut CURRENT_COL: i64 = 1;

// Token storage
let mut TOKENS: [Token; MAX_TOKENS] = [Token { type: TOK_EOF, value: 0, line: 0, column: 0 }; MAX_TOKENS];
let mut TOKEN_COUNT: i64 = 0;

// String table for identifiers and string literals
let mut STRING_TABLE: [i64; MAX_STRING_TABLE] = [0; MAX_STRING_TABLE];
let mut STRING_TABLE_POS: i64 = 0;

// Initialize lexer with input
fn init_lexer(input: String) {
    INPUT_LEN = string_len(input);
    let mut i = 0;
    while i < INPUT_LEN {
        INPUT[i] = string_char_at(input, i);
        i = i + 1;
    }
    INPUT_POS = 0;
    TOKEN_COUNT = 0;
    STRING_TABLE_POS = 0;
    CURRENT_LINE = 1;
    CURRENT_COL = 1;
}

// Get current character
fn current_char() -> i64 {
    if INPUT_POS >= INPUT_LEN {
        return -1;
    }
    return INPUT[INPUT_POS];
}

// Peek next character
fn peek_char() -> i64 {
    if INPUT_POS + 1 >= INPUT_LEN {
        return -1;
    }
    return INPUT[INPUT_POS + 1];
}

// Advance to next character
fn advance() {
    if INPUT_POS < INPUT_LEN {
        if INPUT[INPUT_POS] == 10 { // newline
            CURRENT_LINE = CURRENT_LINE + 1;
            CURRENT_COL = 1;
        } else {
            CURRENT_COL = CURRENT_COL + 1;
        }
        INPUT_POS = INPUT_POS + 1;
    }
}

// Check if character is whitespace
fn is_whitespace(ch: i64) -> bool {
    return ch == 32 || ch == 9 || ch == 10 || ch == 13; // space, tab, LF, CR
}

// Check if character is digit
fn is_digit(ch: i64) -> bool {
    return ch >= 48 && ch <= 57; // '0' to '9'
}

// Check if character is alpha
fn is_alpha(ch: i64) -> bool {
    return (ch >= 97 && ch <= 122) || (ch >= 65 && ch <= 90) || ch == 95; // a-z, A-Z, _
}

// Check if character is alphanumeric
fn is_alnum(ch: i64) -> bool {
    return is_alpha(ch) || is_digit(ch);
}

// Skip whitespace and comments
fn skip_whitespace() {
    while true {
        let ch = current_char();
        if is_whitespace(ch) {
            advance();
        } else if ch == 47 && peek_char() == 47 { // "//"
            // Skip line comment
            advance();
            advance();
            while current_char() != 10 && current_char() != -1 {
                advance();
            }
        } else {
            break;
        }
    }
}

// Add string to string table and return offset
fn add_to_string_table(start: i64, len: i64) -> i64 {
    let offset = STRING_TABLE_POS;
    let mut i = 0;
    while i < len {
        STRING_TABLE[STRING_TABLE_POS] = INPUT[start + i];
        STRING_TABLE_POS = STRING_TABLE_POS + 1;
        i = i + 1;
    }
    STRING_TABLE[STRING_TABLE_POS] = 0; // null terminator
    STRING_TABLE_POS = STRING_TABLE_POS + 1;
    return offset;
}

// Compare string in input with keyword
fn match_keyword(start: i64, len: i64, keyword: String) -> bool {
    if len != string_len(keyword) {
        return false;
    }
    let mut i = 0;
    while i < len {
        if INPUT[start + i] != string_char_at(keyword, i) {
            return false;
        }
        i = i + 1;
    }
    return true;
}

// Add token to array
fn add_token(type: i64, value: i64) {
    if TOKEN_COUNT < MAX_TOKENS {
        TOKENS[TOKEN_COUNT] = Token {
            type: type,
            value: value,
            line: CURRENT_LINE,
            column: CURRENT_COL,
        };
        TOKEN_COUNT = TOKEN_COUNT + 1;
    }
}

// Scan a number
fn scan_number() {
    let start = INPUT_POS;
    let mut value = 0;
    
    while is_digit(current_char()) {
        value = value * 10 + (current_char() - 48);
        advance();
    }
    
    add_token(TOK_NUMBER, value);
}

// Scan an identifier or keyword
fn scan_identifier() {
    let start = INPUT_POS;
    let start_col = CURRENT_COL;
    
    while is_alnum(current_char()) {
        advance();
    }
    
    let len = INPUT_POS - start;
    
    // Check for keywords
    if match_keyword(start, len, "fn") {
        add_token(TOK_FN, 0);
    } else if match_keyword(start, len, "let") {
        add_token(TOK_LET, 0);
    } else if match_keyword(start, len, "mut") {
        add_token(TOK_MUT, 0);
    } else if match_keyword(start, len, "if") {
        add_token(TOK_IF, 0);
    } else if match_keyword(start, len, "else") {
        add_token(TOK_ELSE, 0);
    } else if match_keyword(start, len, "while") {
        add_token(TOK_WHILE, 0);
    } else if match_keyword(start, len, "for") {
        add_token(TOK_FOR, 0);
    } else if match_keyword(start, len, "in") {
        add_token(TOK_IN, 0);
    } else if match_keyword(start, len, "return") {
        add_token(TOK_RETURN, 0);
    } else if match_keyword(start, len, "true") {
        add_token(TOK_TRUE, 0);
    } else if match_keyword(start, len, "false") {
        add_token(TOK_FALSE, 0);
    } else if match_keyword(start, len, "struct") {
        add_token(TOK_STRUCT, 0);
    } else if match_keyword(start, len, "enum") {
        add_token(TOK_ENUM, 0);
    } else if match_keyword(start, len, "pub") {
        add_token(TOK_PUB, 0);
    } else if match_keyword(start, len, "import") {
        add_token(TOK_IMPORT, 0);
    } else if match_keyword(start, len, "i64") {
        add_token(TOK_I64, 0);
    } else if match_keyword(start, len, "i32") {
        add_token(TOK_I32, 0);
    } else if match_keyword(start, len, "bool") {
        add_token(TOK_BOOL, 0);
    } else if match_keyword(start, len, "String") {
        add_token(TOK_STRING_TYPE, 0);
    } else {
        // Regular identifier
        let offset = add_to_string_table(start, len);
        add_token(TOK_IDENT, offset);
    }
}

// Scan a string literal
fn scan_string() {
    advance(); // Skip opening quote
    let start = INPUT_POS;
    
    while current_char() != 34 && current_char() != -1 { // '"'
        if current_char() == 92 { // '\'
            advance(); // Skip escape character
            if current_char() != -1 {
                advance(); // Skip escaped character
            }
        } else {
            advance();
        }
    }
    
    let len = INPUT_POS - start;
    let offset = add_to_string_table(start, len);
    
    if current_char() == 34 {
        advance(); // Skip closing quote
    }
    
    add_token(TOK_STRING, offset);
}

// Main lexing function
fn lex() {
    skip_whitespace();
    
    while current_char() != -1 {
        let ch = current_char();
        
        if is_digit(ch) {
            scan_number();
        } else if is_alpha(ch) {
            scan_identifier();
        } else if ch == 34 { // '"'
            scan_string();
        } else if ch == 40 { // '('
            add_token(TOK_LPAREN, 0);
            advance();
        } else if ch == 41 { // ')'
            add_token(TOK_RPAREN, 0);
            advance();
        } else if ch == 123 { // '{'
            add_token(TOK_LBRACE, 0);
            advance();
        } else if ch == 125 { // '}'
            add_token(TOK_RBRACE, 0);
            advance();
        } else if ch == 91 { // '['
            add_token(TOK_LBRACKET, 0);
            advance();
        } else if ch == 93 { // ']'
            add_token(TOK_RBRACKET, 0);
            advance();
        } else if ch == 59 { // ';'
            add_token(TOK_SEMICOLON, 0);
            advance();
        } else if ch == 44 { // ','
            add_token(TOK_COMMA, 0);
            advance();
        } else if ch == 46 { // '.'
            if peek_char() == 46 { // ".."
                add_token(TOK_DOTDOT, 0);
                advance();
                advance();
            } else {
                add_token(TOK_DOT, 0);
                advance();
            }
        } else if ch == 58 { // ':'
            if peek_char() == 58 { // "::"
                add_token(TOK_COLONCOLON, 0);
                advance();
                advance();
            } else {
                add_token(TOK_COLON, 0);
                advance();
            }
        } else if ch == 45 { // '-'
            if peek_char() == 62 { // "->"
                add_token(TOK_ARROW, 0);
                advance();
                advance();
            } else {
                add_token(TOK_MINUS, 0);
                advance();
            }
        } else if ch == 61 { // '='
            if peek_char() == 61 { // "=="
                add_token(TOK_EQEQ, 0);
                advance();
                advance();
            } else {
                add_token(TOK_EQ, 0);
                advance();
            }
        } else if ch == 33 { // '!'
            if peek_char() == 61 { // "!="
                add_token(TOK_NE, 0);
                advance();
                advance();
            } else {
                add_token(TOK_BANG, 0);
                advance();
            }
        } else if ch == 60 { // '<'
            if peek_char() == 61 { // "<="
                add_token(TOK_LE, 0);
                advance();
                advance();
            } else {
                add_token(TOK_LT, 0);
                advance();
            }
        } else if ch == 62 { // '>'
            if peek_char() == 61 { // ">="
                add_token(TOK_GE, 0);
                advance();
                advance();
            } else {
                add_token(TOK_GT, 0);
                advance();
            }
        } else if ch == 38 { // '&'
            if peek_char() == 38 { // "&&"
                add_token(TOK_AMPAMP, 0);
                advance();
                advance();
            } else {
                // Single & not supported
                advance();
            }
        } else if ch == 124 { // '|'
            if peek_char() == 124 { // "||"
                add_token(TOK_PIPEPIPE, 0);
                advance();
                advance();
            } else {
                // Single | not supported
                advance();
            }
        } else if ch == 43 { // '+'
            add_token(TOK_PLUS, 0);
            advance();
        } else if ch == 42 { // '*'
            add_token(TOK_STAR, 0);
            advance();
        } else if ch == 47 { // '/'
            add_token(TOK_SLASH, 0);
            advance();
        } else if ch == 37 { // '%'
            add_token(TOK_PERCENT, 0);
            advance();
        } else {
            // Unknown character, skip
            advance();
        }
        
        skip_whitespace();
    }
    
    // Add EOF token
    add_token(TOK_EOF, 0);
}

// Get string from string table
fn get_string_from_table(offset: i64) -> String {
    let mut result = "";
    let mut i = offset;
    while STRING_TABLE[i] != 0 {
        result = string_concat(result, string_from_char(STRING_TABLE[i]));
        i = i + 1;
    }
    return result;
}

// Test the lexer
fn test_lexer() {
    let test_code = "
fn main() {
    let x: i64 = 42;
    let msg: String = \"Hello, World!\";
    if x > 0 {
        print(msg);
    }
}
";
    
    print("Testing lexer...");
    init_lexer(test_code);
    lex();
    
    print("Found " + int_to_string(TOKEN_COUNT) + " tokens:");
    
    let mut i = 0;
    while i < TOKEN_COUNT {
        let tok = TOKENS[i];
        if tok.type == TOK_IDENT {
            print("  IDENT: " + get_string_from_table(tok.value));
        } else if tok.type == TOK_NUMBER {
            print("  NUMBER: " + int_to_string(tok.value));
        } else if tok.type == TOK_STRING {
            print("  STRING: \"" + get_string_from_table(tok.value) + "\"");
        } else if tok.type == TOK_FN {
            print("  FN");
        } else if tok.type == TOK_LET {
            print("  LET");
        } else if tok.type == TOK_IF {
            print("  IF");
        } else if tok.type == TOK_I64 {
            print("  I64");
        } else if tok.type == TOK_STRING_TYPE {
            print("  STRING_TYPE");
        } else {
            print("  Token type: " + int_to_string(tok.type));
        }
        i = i + 1;
    }
}