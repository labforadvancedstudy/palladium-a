// Simple Lexer v1 - Basic tokenizer

fn count_tokens(text: String) -> i64 {
    let mut count = 0;
    let mut i = 0;
    
    while i < string_len(text) {
        let ch = string_char_at(text, i);
        
        // Count parentheses
        if ch == 40 || ch == 41 {  // ( or )
            count = count + 1;
        }
        // Count braces
        if ch == 123 || ch == 125 {  // { or }
            count = count + 1;
        }
        // Count semicolons
        if ch == 59 {  // ;
            count = count + 1;
        }
        
        i = i + 1;
    }
    
    return count;
}

fn main() {
    print("Simple Lexer v1\n");
    print("===============\n\n");
    
    let test = "fn main() { print(x); }";
    print("Input: ");
    print(test);
    print("\n");
    
    let tokens = count_tokens(test);
    print("Token count: ");
    print_int(tokens);
    print("\n");
    
    // Generate C code based on token count
    let handle = file_open("lexer_output.c");
    if tokens > 0 {
        file_write(handle, "#include <stdio.h>\nint main(){printf(\"Found tokens!\");return 0;}");
        print("Generated: lexer_output.c\n");
    }
    file_close(handle);
}