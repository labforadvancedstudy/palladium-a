// Bootstrap lexer for Palladium - working within current limitations
// Demonstrates tokenization capabilities

// Token type constants
fn tok_eof() -> i64 { return 0; }
fn tok_ident() -> i64 { return 1; }
fn tok_number() -> i64 { return 2; }
fn tok_string() -> i64 { return 3; }
fn tok_let() -> i64 { return 4; }
fn tok_fn() -> i64 { return 5; }
fn tok_return() -> i64 { return 6; }
fn tok_if() -> i64 { return 7; }
fn tok_lparen() -> i64 { return 8; }
fn tok_rparen() -> i64 { return 9; }
fn tok_lbrace() -> i64 { return 10; }
fn tok_rbrace() -> i64 { return 11; }
fn tok_semi() -> i64 { return 12; }
fn tok_eq() -> i64 { return 13; }
fn tok_plus() -> i64 { return 14; }
fn tok_unknown() -> i64 { return 99; }

// Get token name
fn token_name(t: i64) -> String {
    if t == 0 { return "EOF"; }
    if t == 1 { return "IDENT"; }
    if t == 2 { return "NUMBER"; }
    if t == 3 { return "STRING"; }
    if t == 4 { return "LET"; }
    if t == 5 { return "FN"; }
    if t == 6 { return "RETURN"; }
    if t == 7 { return "IF"; }
    if t == 8 { return "LPAREN"; }
    if t == 9 { return "RPAREN"; }
    if t == 10 { return "LBRACE"; }
    if t == 11 { return "RBRACE"; }
    if t == 12 { return "SEMI"; }
    if t == 13 { return "EQ"; }
    if t == 14 { return "PLUS"; }
    return "UNKNOWN";
}

// Skip whitespace
fn skip_whitespace(input: String, pos: i64) -> i64 {
    let len = string_len(input);
    let mut i = pos;
    
    while i < len {
        let c = string_char_at(input, i);
        if c == 32 { // space
            i = i + 1;
            continue;
        }
        if c == 9 { // tab
            i = i + 1;
            continue;
        }
        if c == 10 { // newline
            i = i + 1;
            continue;
        }
        break;
    }
    
    return i;
}

// Check if letter or underscore
fn is_letter(c: i64) -> bool {
    if c >= 65 {
        if c <= 90 { // A-Z
            return true;
        }
    }
    if c >= 97 {
        if c <= 122 { // a-z
            return true;
        }
    }
    if c == 95 { // underscore
        return true;
    }
    return false;
}

// Get identifier length
fn get_ident_len(input: String, start: i64) -> i64 {
    let len = string_len(input);
    let mut i = start;
    
    if i >= len {
        return 0;
    }
    
    if is_letter(string_char_at(input, i)) == false {
        return 0;
    }
    
    i = i + 1;
    
    while i < len {
        let c = string_char_at(input, i);
        if is_letter(c) {
            i = i + 1;
            continue;
        }
        if char_is_digit(c) {
            i = i + 1;
            continue;
        }
        break;
    }
    
    return i - start;
}

// Check if keyword
fn check_keyword(s: String) -> i64 {
    if string_eq(s, "let") { return tok_let(); }
    if string_eq(s, "fn") { return tok_fn(); }
    if string_eq(s, "return") { return tok_return(); }
    if string_eq(s, "if") { return tok_if(); }
    return tok_ident();
}

// Get next token type at position
fn get_token_at(input: String, pos: i64) -> i64 {
    let start = skip_whitespace(input, pos);
    let len = string_len(input);
    
    if start >= len {
        return tok_eof();
    }
    
    let c = string_char_at(input, start);
    
    // Single character tokens
    if c == 40 { return tok_lparen(); }  // (
    if c == 41 { return tok_rparen(); }  // )
    if c == 123 { return tok_lbrace(); } // {
    if c == 125 { return tok_rbrace(); } // }
    if c == 59 { return tok_semi(); }    // ;
    if c == 61 { return tok_eq(); }      // =
    if c == 43 { return tok_plus(); }    // +
    
    // Numbers
    if char_is_digit(c) {
        return tok_number();
    }
    
    // Identifiers/keywords
    if is_letter(c) {
        let ident_len = get_ident_len(input, start);
        if ident_len > 0 {
            let ident = string_substring(input, start, start + ident_len);
            return check_keyword(ident);
        }
    }
    
    // Strings
    if c == 34 { // quote
        return tok_string();
    }
    
    return tok_unknown();
}

// Get token length
fn get_token_len(input: String, pos: i64) -> i64 {
    let start = skip_whitespace(input, pos);
    let len = string_len(input);
    
    if start >= len {
        return 0;
    }
    
    let c = string_char_at(input, start);
    
    // Single chars
    if c == 40 { return 1; }  // (
    if c == 41 { return 1; }  // )
    if c == 123 { return 1; } // {
    if c == 125 { return 1; } // }
    if c == 59 { return 1; }  // ;
    if c == 61 { return 1; }  // =
    if c == 43 { return 1; }  // +
    
    // Numbers
    if char_is_digit(c) {
        let mut i = start;
        while i < len {
            if char_is_digit(string_char_at(input, i)) == false {
                break;
            }
            i = i + 1;
        }
        return i - start;
    }
    
    // Identifiers
    if is_letter(c) {
        return get_ident_len(input, start);
    }
    
    // Strings (simple - find closing quote)
    if c == 34 { // quote
        let mut i = start + 1;
        while i < len {
            if string_char_at(input, i) == 34 {
                return i - start + 1;
            }
            i = i + 1;
        }
        return 1; // unterminated
    }
    
    return 1; // unknown
}

// Tokenize and display
fn tokenize(input: String) {
    print("Input:");
    print(input);
    print("Tokens:");
    
    let len = string_len(input);
    let mut pos = 0;
    let mut count = 0;
    
    while pos < len {
        let old_pos = pos;
        pos = skip_whitespace(input, pos);
        
        if pos >= len {
            break;
        }
        
        let tok_type = get_token_at(input, pos);
        let tok_len = get_token_len(input, pos);
        
        if tok_len == 0 {
            break;
        }
        
        let tok_text = string_substring(input, pos, pos + tok_len);
        let tok_name: String = token_name(tok_type);
        
        print(string_concat("  ", string_concat(tok_name, string_concat(": ", tok_text))));
        
        pos = pos + tok_len;
        count = count + 1;
        
        if count > 50 { // safety
            break;
        }
    }
    
    print(string_concat("Total tokens: ", string_from_char(48 + count)));
    print("");
}

fn main() {
    print("=== Palladium Bootstrap Lexer ===\n");
    
    print("Test 1: Variable declaration");
    tokenize("let x = 42;");
    
    print("Test 2: Function");
    tokenize("fn hello() { return 123; }");
    
    print("Test 3: Expression");
    tokenize("result = (a + b);");
    
    print("Test 4: String");
    tokenize("let msg = \"Hello\";");
    
    print("=== Lexer complete ===");
    print("This demonstrates that Palladium can tokenize its own syntax!");
}